import asyncio
import time
import os
from typing import List, Optional
from dotenv import load_dotenv, find_dotenv
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from backend.RateLimiter import RateLimiter
from backend.db_utils import load_products_to_categorize, save_categorizations_to_db

try:
    import tiktoken

    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    print("‚ö†Ô∏è  tiktoken not installed. Token estimation will be approximate.")
    print("   Install with: pip install tiktoken")

from backend.db_utils import connect_to_db

load_dotenv(find_dotenv())

CATEGORIES = {
    "–ù–∞–º–∏—Ä–Ω–∏—Ü–∏": ['–ë—Ä–∞—à–Ω–æ', '–î–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ —ò–∞–¥–µ—ö–∞', '–î–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –∫–æ–Ω–∑–µ—Ä–≤–∏—Ä–∞—ö–µ', '–ì–æ—Ç–æ–≤–∏ –æ–±—Ä–æ—Ü–∏', '–à–∞—ò—Ü–∞',
                  '–ö–µ—á–∞–ø –∏ —Å–æ—Å –æ–¥ –¥–æ–º–∞—Ç–∏', '–ö–≤–∞—Å–µ—Ü', '–ú–∞—ò–æ–Ω–µ–∑, —Å–µ–Ω—Ñ, —Ä–µ–Ω, –ø—Ä–µ–ª–∏–≤–∏, —Å–æ—Å–æ–≤–∏', '–ú–∞—Ä–≥–∞—Ä–∏–Ω',
                  '–ú–µ—à–∞–≤–∏–Ω–∞ –æ–¥ –∑–∞—á–∏–Ω–∏', '–ó—Ä–Ω–µ—Å—Ç–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏', '–ü—É–¥–∏–Ω–≥ –∏ —à–ª–∞–≥', '–®–µ—ú–µ—Ä', '–û—Ü–µ—Ç', '–°–æ–ª', '–ü–µ–∫–∞—Ä–∞',
                  '–°—É–ø–∏ –∏ —á–æ—Ä–±–∏', '–°√® –∑–∞ —Ç–æ—Ä—Ç–∏ –∏ –∫–æ–ª–∞—á–∏', '–¢–µ—Å—Ç–µ–Ω–∏–Ω–∏', '–¢–æ—Ä—Ç–∏—ô–∏', '–ú–∞—Å–ª–æ', '–ó–∞—á–∏–Ω–∏', '–ü–∏—Ä–µ'],
    "–ó–¥—Ä–∞–≤–∞ —Ö—Ä–∞–Ω–∞": ['–ë–µ–∑–≥–ª—É—Ç–µ–Ω—Å–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏', '–†–∞—Å—Ç–∏—Ç–µ–ª–Ω–∏ –Ω–∞–ø–∏—Ç–æ—Ü–∏', '–ï–∫—Å–ø–∞–Ω–¥–∏—Ä–∞–Ω –æ—Ä–∏–∑', '–ò–Ω—Ç–µ–≥—Ä–∞–ª–µ–Ω –æ—Ä–∏–∑',
                     '–ò–Ω—Ç–µ–≥—Ä–∞–ª–Ω–∏ –∫–æ–ª–∞—á–∏', '–ú–µ–¥', '–û–≤–µ—Å–Ω–∞ –∫–∞—à–∞', '–°–Ω–µ–≥—É–ª–∫–∏ –∏ –º—É—Å–ª–∏', '–°–æ–ª–µ–Ω–∏ –≥—Ä–∏—Ü–∫–∏', '–®—É–º–ª–∏–≤–∏ —Ç–∞–±–ª–µ—Ç–∏',
                     '–°–µ–º–∫–∏ –∏ —Å–µ–º–∫–∏ —Å–æ –ª—É—à–ø–∞', '–°—É–≤–∏ –æ–≤–æ—à—ò–∞', '–ó–∞—Å–ª–∞–¥—É–≤–∞—á–∏', '–ó–¥—Ä–∞–≤–∏ –Ω–∞–º–∞–∑–∏',
                     '–ó–¥—Ä–∞–≤–∏ –≥—Ä–∏—Ü–∫–∏ –∏ –ø–∏—ò–∞–ª–æ—Ü–∏', '–î–≤–æ–ø–µ–∫', '–ü—Ä–æ—Ç–µ–∏–Ω –æ–¥ —Å—É—Ä—É—Ç–∫–∞', '–ó—Ä–Ω–µ—Å—Ç–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏'],
    "–ú–ª–µ—á–Ω–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏": ['–ú–ª–µ–∫–æ', '–à–æ–≥—É—Ä—Ç', '–ü—É—Ç–µ—Ä', '–ú–ª–µ—á–Ω–∏ –¥–µ—Å–µ—Ä—Ç–∏', '–ú–ª–µ—á–Ω–∏ –ø–∏—ò–∞–ª–æ—Ü–∏', '–ö–∏—Å–µ–ª–æ –º–ª–µ–∫–æ',
                         '–ö–∏—Å–µ–ª–∞ –ø–∞–≤–ª–∞–∫–∞', '–ì—Ä—á–∫–∏ —ò–æ–≥—É—Ä—Ç', '–°–∏—Ä–µ—ö–∞', '–ù–∞–º–∞–∑–∏ –æ–¥ —Å–∏—Ä–µ—ö–µ', '–°—É—Ä—É—Ç–∫–∞',
                         '–ü—Ä–µ—Ä–∞–±–æ—Ç–µ–Ω–æ —Å–∏—Ä–µ—ö–µ', '–û–≤–æ—à–µ–Ω —ò–æ–≥—É—Ä—Ç'],
    "–û–≤–æ—à—ò–µ –∏ –∑–µ–ª–µ–Ω—á—É–∫": ['–ó–µ–ª–µ–Ω—á—É–∫', '–û–≤–æ—à—ò–µ', '–ö–æ–Ω–∑–µ—Ä–≤–∏—Ä–∞–Ω –∑–µ–ª–µ–Ω—á—É–∫', '–ö–æ–Ω–∑–µ—Ä–≤–∏—Ä–∞–Ω–æ –æ–≤–æ—à—ò–µ'],
    "–ú–µ—Å–æ –∏ —Ä–∏–±–∞": ['–ö–æ–ª–±–∞—Å–∏', '–ö–æ–Ω–∑–µ—Ä–≤–∏—Ä–∞–Ω–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏', '–ù–∞–º–∞–∑–∏', '–ü–∞—à—Ç–µ—Ç–∞', '–°—É–≤–æ–º–µ—Å–Ω–∞—Ç–æ –∏ –ø—Ä–æ—Ü–µ—Å–∏—Ä–∞–Ω–æ –º–µ—Å–æ',
                    '–°–∞–ª–∞–º–∞', '–ù–∞ —Ç–µ–Ω–∫–∏ –ø–∞—Ä—á–∏—ö–∞', '–°–≤–µ–∂–∞ —Ä–∏–±–∞', '–°–≤–µ–∂–æ –º–µ—Å–æ', '–í–∏—Ä—à–ª–∏ –∏ –∫–æ–ª–±–∞—Å–∏—Ü–∏'],
    "–ó–∞–º—Ä–∑–Ω–∞—Ç–æ": ['–ì–æ—Ç–æ–≤–∏ —Å–ª–∞–¥–æ–ª–µ–¥–∏', '–†–∏–±–∞ –∏ –º–æ—Ä—Å–∫–∞ —Ö—Ä–∞–Ω–∞', '–ó–∞–º—Ä–∑–Ω–∞—Ç –∑–µ–ª–µ–Ω—á—É–∫', '–ó–∞–º—Ä–∑–Ω–∞—Ç–æ —Ç–µ—Å—Ç–æ –∏ –ø–µ—Ü–∏–≤–∞',
                  '–ó–∞–º—Ä–∑–Ω–∞—Ç–æ –æ–≤–æ—à—ò–µ', '–ó–∞–º—Ä–∑–Ω–∞—Ç–æ –º–µ—Å–æ'],
    "–ü–∏—ò–∞–ª–æ—Ü–∏": ['–í–æ–¥–∞', '–ö–∞—Ñ–µ', '–ì–∞–∑–∏—Ä–∞–Ω–∏ —Å–æ–∫–æ–≤–∏', '–ö–∞–ø—Å—É–ª–∏ –∑–∞ –∫–∞—Ñ–µ', '–ï–Ω–µ—Ä–≥–µ—Ç—Å–∫–∏ –ø–∏—ò–∞–ª–æ—Ü–∏', '–ß–∞–µ–≤–∏', '–õ–∞–¥–µ–Ω–∏ —á–∞–µ–≤–∏',
                 '–ù–µ–≥–∞–∑–∏—Ä–∞–Ω–∏ —Å–æ–∫–æ–≤–∏'],
    "–ê–ª–∫–æ—Ö–æ–ª–Ω–∏ –ø–∏—ò–∞–ª–æ—Ü–∏": ['–ü–∏–≤–æ', '–à–∞–∫–∏ –∞–ª–∫–æ—Ö–æ–ª–Ω–∏ –ø–∏—ò–∞–ª–æ—Ü–∏', '–í–∏–Ω–æ', '–í–∏—Ç–∞–º–∏–Ω—Å–∫–∏ –ø–∏—ò–∞–ª–æ—Ü–∏', '–ö–≤–∞—Å', '–ö–æ–∫—Ç–µ–ª',
                           '–®–∞–º–ø–∞—ö—Å–∫–æ –∏ –ø–µ–Ω–ª–∏–≤–æ –≤–∏–Ω–æ'],
    "–°–ª–∞—Ç–∫–∏ –∏ –≥—Ä–∏—Ü–∫–∏": ['–ë–æ–Ω–±–æ–Ω–∏', '–ë–æ–Ω–±–æ—ö–µ—Ä–∞', '–ß–æ–∫–æ–ª–∞–¥–∏', '–ß–æ–∫–æ–ª–∞–¥–Ω–∏ –±–∞—Ä–æ–≤–∏', '–î–µ—Å–µ—Ä—Ç–∏', '–î–æ–¥–∞—Ç–æ—Ü–∏ –∑–∞ –º–ª–µ–∫–æ',
                        '–ì—Ä–∏—Ü–∫–∏', '–ö–µ–∫—Å, –≤–∞—Ñ–ª–∏, –±–∏—Å–∫–≤–∏—Ç', '–ö—Ä–µ–º–æ–≤–∏', '–ö—Ä–æ–∞—Å–∞–Ω–∏', '–ù–∞–ø–æ–ª–∏—Ç–∞–Ω–∫–∏', '–†–æ–ª–∞—Ç–∏',
                        '–ì—É–º–∏ –∑–∞ —ü–≤–∞–∫–∞—ö–µ', '–°–ª–∞—Ç–∫–∏ –Ω–∞–º–∞–∑–∏', '–î–∏–µ—Ç–∞–ª–Ω–∏ –∏ –∑–¥—Ä–∞–≤–∏ —Å–ª–∞—Ç–∫–∏'],
    "–õ–∏—á–Ω–∞ —Ö–∏–≥–∏–µ–Ω–∞ –∏ –∫–æ–∑–º–µ—Ç–∏–∫–∞": ['–°–∞–ø—É–Ω–∏', '–ß–∏—Å—Ç–µ—ö–µ –Ω–∞ –ª–∏—Ü–µ—Ç–æ', '–ë—Ä–∏—á–µ–≤–∏', '–ë–æ—ò–∞ –∑–∞ –∫–æ—Å–∞', '–ì–µ–ª–æ–≤–∏ –∑–∞ —Ç—É—à–∏—Ä–∞—ö–µ',
                                  '–•–∏–≥–∏–µ–Ω–∞ –∑–∞ –∂–µ–Ω–∏', '–î–µ–∑–æ–¥–æ—Ä–∞–Ω—Å–∏', '–ù–µ–≥–∞ –∑–∞ –∫–æ—Å–∞', '–ù–µ–≥–∞ –Ω–∞ –ª–∏—Ü–µ', '–ù–µ–≥–∞ –Ω–∞ —Ä–∞—Ü–µ',
                                  '–ù–µ–≥–∞ –Ω–∞ —Å—Ç–∞–ø–∞–ª–∞', '–ù–µ–≥–∞ –∑–∞ —Ç–µ–ª–æ', '–û—Ä–∞–ª–Ω–∞ —Ö–∏–≥–∏–µ–Ω–∞', '–•–∞—Ä—Ç–∏—ò–∞ –∫–æ–Ω—Ñ–µ–∫—Ü–∏—ò–∞',
                                  '–ü—Ä–µ–ø–∞—Ä–∞—Ç–∏ –∑–∞ —Å–æ–Ω—á–∞—ö–µ', '–°—Ç–∏–∫ –∏ —Ä–æ–ª-–æ–Ω', '–°–µ—Ç–æ–≤–∏ –∑–∞ –ø–æ–∫–ª–æ–Ω', '–õ–∞–±–µ–ª–æ',
                                  '–ü—Ä–æ–∏–∑–≤–æ–¥–∏ –∑–∞ –±—Ä–∏—á–µ—ö–µ', '–°—Ç–∞–ø—á–∏—ö–∞ –∑–∞ —É—à–∏', '–ö–æ–Ω–¥–æ–º–∏', '–ü–∞—Ä—Ñ–µ–º–∏'],
    "–î–æ–º–∞—à–Ω–∞ —Ö–µ–º–∏—ò–∞": ['–î–µ—Ç–µ—Ä–≥–µ–Ω—Ç –∑–∞ —Å–∞–¥–æ–≤–∏', '–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª–Ω–∞ –Ω–µ–≥–∞ –Ω–∞ –∞–ª–∏—à—Ç–∞', '–ò–Ω—Å–µ–∫—Ç–∏—Ü–∏–¥–∏', '–ö–∞–ø—Å—É–ª–∏ –∑–∞ –ø–µ—Ä–µ—ö–µ –∞–ª–∏—à—Ç–∞',
                       '–ú–∞—Ä–∞–º—á–∏—ö–∞ –∑–∞ –ø–µ—Ä–µ—ö–µ –∞–ª–∏—à—Ç–∞', '–û–º–µ–∫–Ω—É–≤–∞—á –∑–∞ –∞–ª–∏—à—Ç–∞', '–ü—Ä–∞—à–æ–∫ –∑–∞ –ø–µ—Ä–µ—ö–µ –∞–ª–∏—à—Ç–∞',
                       '–¢–µ—á–Ω–∏ –¥–µ—Ç–µ—Ä–≥–µ–Ω—Ç–∏ –∑–∞ –ø–µ—Ä–µ—ö–µ –∞–ª–∏—à—Ç–∞', '–û—Å–≤–µ–∂—É–≤–∞—á–∏ –Ω–∞ –ø—Ä–æ—Å—Ç–æ—Ä', '–ú–∞—à–∏–Ω—Å–∫–æ –º–∏–µ—ö–µ —Å–∞–¥–æ–≤–∏',
                       '–°—Ä–µ–¥—Å—Ç–≤–∞ –∑–∞ —á–∏—Å—Ç–µ—ö–µ', '–°—Ä–µ–¥—Å—Ç–≤–∞ –∑–∞ —á–∏—Å—Ç–µ—ö–µ –Ω–∞ –¥–æ–º–∞—ú–∏–Ω—Å—Ç–≤–æ', '–°—Ä–µ–¥—Å—Ç–≤–∞ –∑–∞ —á–∏—Å—Ç–µ—ö–µ –Ω–∞ —Å–∞–Ω–∏—Ç–∞—Ä–∏–∏',
                       '–ù–µ–≥–∞ –Ω–∞ –æ–±—É–≤–∫–∏', '–û—Å–≤–µ–∂—É–≤–∞—á–∏ –Ω–∞ —Ç–æ–∞–ª–µ—Ç', '–û–ø—Ä–µ–º–∞ –∑–∞ —á–∏—Å—Ç–µ—ö–µ'],
    "–ö–∞—Ç—á–µ –∑–∞ –±–µ–±–∏—ö–∞": ['–î–µ—Ç—Å–∫–∞ —Ö–∏–≥–∏–µ–Ω–∞', '–•—Ä–∞–Ω–∞ –∑–∞ –±–µ–±–∏—ö–∞', '–ö–∞—à–∞ –∑–∞ –¥–µ—Ü–∞', '–ü–∏—ò–∞–ª–æ—Ü–∏', '–ü–µ–ª–µ–Ω–∏',
                        '–ó–∞–º–µ–Ω–∞ –∑–∞ –º–ª–µ–∫–æ –∑–∞ –¥–µ—Ü–∞'],
    "–î–æ–º–∞—à–Ω–∏ –º–∏–ª–µ–Ω–∏—Ü–∏": ['–ê–Ω—Ç–∏–ø–∞—Ä–∞–∑–∏—Ç—Å–∫–∏ –ª–µ–∫–æ–≤–∏', '–í–ª–∞–∂–Ω–∞ —Ö—Ä–∞–Ω–∞ –∑–∞ –º–∞—á–∫–∏', '–í–ª–∞–∂–Ω–∞ —Ö—Ä–∞–Ω–∞ –∑–∞ –∫—É—á–∏—ö–∞', '–ì—Ä–∏—Ü–∫–∏ –∑–∞ –º–∞—á–∫–∏',
                         '–ì—Ä–∏—Ü–∫–∏ –∑–∞ –∫—É—á–∏—ö–∞', '–°—É–≤–∞ —Ö—Ä–∞–Ω–∞ –∑–∞ –º–∞—á–∫–∏', '–°—É–≤–∞ —Ö—Ä–∞–Ω–∞ –∑–∞ –∫—É—á–∏—ö–∞'],
    "–î–æ–º –∏ –≥—Ä–∞–¥–∏–Ω–∞": ['–ö—É—ò–Ω—Å–∫–∏ –ø—Ä–∏–±–æ—Ä –∏ —Å–∞–¥–æ–≤–∏', '–°–∏—ò–∞–ª–∏—Ü–∏', '–ë–∞—Ç–µ—Ä–∏–∏', '–°—É–ø–µ—Ä –ª–µ–ø–∞–∫', '–ß–µ–ø–∫–∞–ª–∫–∏ –∑–∞ –∑–∞–±–∏', '–°–≤–µ—ú–∏', '–°–∞–ª—Ñ–µ—Ç–∏'],
    "–¶–∏–≥–∞—Ä–∏": ['–¶–∏–≥–∞—Ä–∏ –∏ –Ω–∏–∫–æ—Ç–∏–Ω—Å–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏'],
    "–†–∞–∑–Ω–æ": ['–û—Å—Ç–∞–Ω–∞—Ç–æ']
}

TAXONOMY_COMPRESSED = "\n".join([
    f"{main}: {', '.join(subs)}"
    for main, subs in CATEGORIES.items()
])

class ProductCategory(BaseModel):
    """Single product categorization."""
    main_category: str = Field(description="Main category from taxonomy")
    sub_category: str = Field(description="Subcategory belonging to main category")
    confidence: float = Field(description="Confidence 0.0-1.0", ge=0.0, le=1.0)
    reasoning: Optional[str] = Field(default=None, description="Brief explanation")

class BatchProductCategories(BaseModel):
    """Multiple product categorizations in a single response."""
    products: List[ProductCategory] = Field(description="List of categorizations in order")


rate_limiter = RateLimiter(rpm_limit=14, tpm_limit=200000)  # Conservative limits for GPT-4o mini

def estimate_tokens(products: List[dict]) -> int:
    """
    Estimate tokens for a batch of products.

    Args:
        products: List of product dicts with 'name', 'description', 'existing_categories'

    Returns:
        Estimated total tokens (input + output)
    """
    if TIKTOKEN_AVAILABLE:
        try:
            encoding = tiktoken.encoding_for_model("gpt-5.1")
        except:
            encoding = tiktoken.get_encoding("cl100k_base")
    else:
        encoding = None

    # System prompt + taxonomy (approximately constant)
    system_tokens = 350  # System prompt
    taxonomy_tokens = 800  # Compressed taxonomy

    # User content for all products
    user_content = "\n\n".join([
        f"Product {i + 1}:\nName: {p.get('name', '')}\n"
        f"Description: {p.get('description', '–ù–µ–º–∞ –æ–ø–∏—Å')}\n"
        f"Source: {p.get('existing_categories', '–ù–µ–º–∞')}"
        for i, p in enumerate(products)
    ])

    if encoding:
        user_tokens = len(encoding.encode(user_content))
    else:
        # Rough approximation: 1 token ‚âà 4 characters for Macedonian
        user_tokens = len(user_content) // 4

    # Output tokens: ~100 per product (category info + reasoning)
    output_tokens = len(products) * 100

    total = system_tokens + taxonomy_tokens + user_tokens + output_tokens

    return total

def create_batch_prompt() -> ChatPromptTemplate:
    """Create optimized prompt for batch categorization."""

    prompt = ChatPromptTemplate.from_messages([
        ("system", """You are a product categorization expert for Macedonian supermarkets.

Categorize ALL products below into ONE main category and ONE subcategory from this taxonomy:

{taxonomy}

RULES:
1. Choose most specific and relevant category
2. If multiple categories fit, choose primary use case
3. Confidence scoring:
   - 0.9-1.0: Clear match (e.g., "–ú–ª–µ–∫–æ" ‚Üí –ú–ª–µ—á–Ω–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏/–ú–ª–µ–∫–æ)
   - 0.7-0.89: Good match, minor ambiguity
   - 0.5-0.69: Multiple options, chose most likely
   - <0.5: Uncertain, needs review
4. Subcategory MUST belong to chosen main category
5. Return categorizations IN THE SAME ORDER as input products

Keep reasoning brief (1 sentence)."""),

        ("user", """{products_text}

Return a JSON object with a "products" array containing categorizations for ALL products above, in order.""")
    ])

    return prompt


async def categorize_batch_gpt(
        products_chunk: List[dict],
        openai_api_key: str
) -> List[ProductCategory]:
    """
    Categorize a batch of products.

    Args:
        products_chunk: List of 3-8 products to categorize in one request
        openai_api_key: OpenAI API key

    Returns:
        List of ProductCategory objects
    """
    products_text = "\n\n".join([
        f"Product {i + 1}:\n"
        f"Name: {p.get('name', '')}\n"
        f"Description: {p.get('description', '–ù–µ–º–∞ –æ–ø–∏—Å')}\n"
        f"Source categories: {p.get('existing_categories', '–ù–µ–º–∞')}"
        for i, p in enumerate(products_chunk)
    ])

    llm = ChatOpenAI(
        model="gpt-5.1",
        temperature=0.1,
        api_key=openai_api_key,
        max_retries=2
    )

    structured_llm = llm.with_structured_output(BatchProductCategories)

    prompt = create_batch_prompt()
    chain = prompt | structured_llm

    try:
        # Invoke
        result = await chain.ainvoke({
            "taxonomy": TAXONOMY_COMPRESSED,
            "products_text": products_text
        })

        # Validate we got the right number of results
        if len(result.products) != len(products_chunk):
            print(f"‚ö†Ô∏è  Warning: Expected {len(products_chunk)} results, got {len(result.products)}")

            # Pad with error entries if needed
            while len(result.products) < len(products_chunk):
                result.products.append(ProductCategory(
                    main_category="–†–∞–∑–Ω–æ",
                    sub_category="–û—Å—Ç–∞–Ω–∞—Ç–æ",
                    confidence=0.0,
                    reasoning="Missing from batch response"
                ))

        return result.products[:len(products_chunk)]  # Ensure exact match

    except Exception as e:
        print(f"‚ùå Batch error: {e}")
        # Return error categorizations for all products in batch
        return [
            ProductCategory(
                main_category="–†–∞–∑–Ω–æ",
                sub_category="–û—Å—Ç–∞–Ω–∞—Ç–æ",
                confidence=0.0,
                reasoning=f"Error: {str(e)}"
            )
            for _ in products_chunk
        ]


async def categorize_all_products(
        products: List[dict],
        batch_size: int = 5,
        concurrency: int = 16,
        openai_api_key: str = None
) -> List[dict]:
    """
    Categorize all products with batching and rate limiting.

    Args:
        products: List of product dicts
        batch_size: Number of products per API request (3-8 recommended)
        concurrency: Number of concurrent batches (5-10 recommended for GPT-4o mini)
        openai_api_key: OpenAI API key (or set OPENAI_API_KEY env var)

    Returns:
        List of products with 'categorization' field added
    """
    if not openai_api_key:
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEY not found in environment or arguments")

    print(f"üöÄ Starting categorization of {len(products)} products")
    print(f"   Model: GPT-5.1")
    print(f"   Batch size: {batch_size} products/request")
    print(f"   Concurrency: {concurrency} concurrent batches")
    print(f"   Estimated requests: {len(products) // batch_size + 1}")
    print(f"   Estimated cost: ~${(len(products) / 1000) * 0.15:.2f}")
    print()

    # Split products into batches
    batches = []
    for i in range(0, len(products), batch_size):
        batches.append(products[i:i + batch_size])

    # Semaphore for concurrency control
    semaphore = asyncio.Semaphore(concurrency)

    # Progress tracking
    completed = 0
    start_time = time.time()

    async def process_batch(batch_idx: int, batch: List[dict]):
        nonlocal completed

        async with semaphore:
            # Estimate tokens and acquire rate limit
            estimated_tokens = estimate_tokens(batch)
            await rate_limiter.acquire(estimated_tokens)

            # Categorize batch
            categorizations = await categorize_batch_gpt(batch, openai_api_key)

            # Assign results
            for product, cat in zip(batch, categorizations):
                product['categorization'] = cat.model_dump()

            # Update progress
            completed += len(batch)
            elapsed = time.time() - start_time
            rate = completed / elapsed if elapsed > 0 else 0
            eta = (len(products) - completed) / rate if rate > 0 else 0

            if batch_idx % 10 == 0 or completed == len(products):
                stats = rate_limiter.get_stats()
                print(f"‚úì {completed:,}/{len(products):,} products "
                      f"({completed * 100 // len(products)}%) | "
                      f"{rate:.1f} products/sec | "
                      f"ETA: {eta / 60:.1f}m | "
                      f"RPM: {stats['current_rpm']}/{stats['rpm_limit']}")

            return batch

    # Process all batches concurrently
    tasks = [process_batch(i, batch) for i, batch in enumerate(batches)]
    await asyncio.gather(*tasks)

    # Final stats
    elapsed = time.time() - start_time
    stats = rate_limiter.get_stats()
    estimated_cost = (stats['total_tokens'] / 1_000_000) * 0.15  # $0.15 per 1M tokens for gpt-4o-mini

    print()
    print("=" * 70)
    print(f"‚úÖ Categorization complete!")
    print(f"   Total products: {len(products):,}")
    print(f"   Total time: {elapsed / 60:.2f} minutes")
    print(f"   Average rate: {len(products) / elapsed:.1f} products/sec")
    print(f"   Total API requests: {stats['total_requests']:,}")
    print(f"   Total tokens used: {stats['total_tokens']:,}")
    print(f"   Estimated cost: ${estimated_cost:.2f}")
    print("=" * 70)

    return products


async def main():
    """Main execution function."""

    # Check for OpenAI API key
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("‚ùå ERROR: OPENAI_API_KEY not found!")
        return

    # Connect to database
    db = connect_to_db('products_categorized')

    # Load products
    # For testing: limit_per_collection=50
    # For production: limit_per_collection=None
    products, products_markets = load_products_to_categorize(
        db,
        limit_per_collection=6100  # Remove this or set to None for all products
    )

    if not products:
        print("‚úÖ No products need categorization!")
        db.client.close()
        return

    # Categorize all products
    categorized_products = await categorize_all_products(
        products,
        batch_size=64,  # products per request
        concurrency=32,  # concurrent batches
        openai_api_key=openai_api_key
    )

    # Save to database
    save_categorizations_to_db(db, categorized_products, products_markets)

    # Analyze results
    print("\nüìà Categorization Quality Analysis:")
    confidence_ranges = {
        'High (0.9-1.0)': 0,
        'Good (0.7-0.89)': 0,
        'Medium (0.5-0.69)': 0,
        'Low (<0.5)': 0,
        'Errors': 0
    }

    for p in categorized_products:
        conf = p['categorization'].get('confidence', 0)
        if p['categorization'].get('main_category') is None:
            confidence_ranges['Errors'] += 1
        elif conf >= 0.9:
            confidence_ranges['High (0.9-1.0)'] += 1
        elif conf >= 0.7:
            confidence_ranges['Good (0.7-0.89)'] += 1
        elif conf >= 0.5:
            confidence_ranges['Medium (0.5-0.69)'] += 1
        else:
            confidence_ranges['Low (<0.5)'] += 1

    for range_name, count in confidence_ranges.items():
        percentage = (count / len(categorized_products) * 100) if categorized_products else 0
        print(f"   {range_name}: {count:,} ({percentage:.1f}%)")

    # Show some examples
    print("\nüìã Sample categorizations:")
    for i, p in enumerate(categorized_products[:5]):
        cat = p['categorization']
        print(f"\n{i + 1}. {p['name'][:60]}")
        print(f"   ‚Üí {cat['main_category']} / {cat['sub_category']}")
        print(f"   Confidence: {cat['confidence']:.2f}")
        if cat.get('reasoning'):
            print(f"   Reasoning: {cat['reasoning'][:80]}")

    # Close database
    db.client.close()

    print("\n‚úÖ All done!")


if __name__ == "__main__":
    asyncio.run(main())